{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":120005,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":100936,"modelId":121027}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n%pip install -U transformers \n%pip install -U datasets \n%pip install -U accelerate \n%pip install -U peft \n%pip install -U trl \n%pip install -U bitsandbytes \n%pip install -U wandb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-09T14:19:13.598395Z","iopub.execute_input":"2025-05-09T14:19:13.598680Z","iopub.status.idle":"2025-05-09T14:19:36.092473Z","shell.execute_reply.started":"2025-05-09T14:19:13.598659Z","shell.execute_reply":"2025-05-09T14:19:36.091677Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"from transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import (\n    LoraConfig,\n    PeftModel,\n    prepare_model_for_kbit_training,\n    get_peft_model,\n)\nimport os, torch, wandb\nfrom datasets import load_dataset\nfrom trl import SFTTrainer, setup_chat_format","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T14:19:36.094034Z","iopub.execute_input":"2025-05-09T14:19:36.094287Z","iopub.status.idle":"2025-05-09T14:19:36.099625Z","shell.execute_reply.started":"2025-05-09T14:19:36.094265Z","shell.execute_reply":"2025-05-09T14:19:36.098974Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nhf_token = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\nlogin(token = hf_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T14:19:36.100289Z","iopub.execute_input":"2025-05-09T14:19:36.100494Z","iopub.status.idle":"2025-05-09T14:19:36.313338Z","shell.execute_reply.started":"2025-05-09T14:19:36.100480Z","shell.execute_reply":"2025-05-09T14:19:36.312498Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"wb_token = user_secrets.get_secret(\"wandb\")\n\nwandb.login(key=wb_token)\nrun = wandb.init(\n    project='Fine-tune Llama 3.2 on Customer Support Dataset', \n    job_type=\"training\", \n    anonymous=\"allow\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T14:19:36.315383Z","iopub.execute_input":"2025-05-09T14:19:36.315633Z","iopub.status.idle":"2025-05-09T14:19:43.343634Z","shell.execute_reply.started":"2025-05-09T14:19:36.315600Z","shell.execute_reply":"2025-05-09T14:19:43.342906Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing previous runs because reinit is set to 'default'."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">magic-snowflake-1</strong> at: <a href='https://wandb.ai/nanew/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/wuntu6jm?apiKey=caa854bcf02f1a45ec737cc926418472288799ed' target=\"_blank\">https://wandb.ai/nanew/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/wuntu6jm?apiKey=caa854bcf02f1a45ec737cc926418472288799ed</a><br> View project at: <a href='https://wandb.ai/nanew/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset?apiKey=caa854bcf02f1a45ec737cc926418472288799ed' target=\"_blank\">https://wandb.ai/nanew/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset?apiKey=caa854bcf02f1a45ec737cc926418472288799ed</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250509_141114-wuntu6jm/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.11"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250509_141936-nhky0pk4</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/nanew/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/nhky0pk4?apiKey=caa854bcf02f1a45ec737cc926418472288799ed' target=\"_blank\">helpful-oath-2</a></strong> to <a href='https://wandb.ai/nanew/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset?apiKey=caa854bcf02f1a45ec737cc926418472288799ed' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/nanew/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset?apiKey=caa854bcf02f1a45ec737cc926418472288799ed' target=\"_blank\">https://wandb.ai/nanew/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset?apiKey=caa854bcf02f1a45ec737cc926418472288799ed</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/nanew/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/nhky0pk4?apiKey=caa854bcf02f1a45ec737cc926418472288799ed' target=\"_blank\">https://wandb.ai/nanew/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/nhky0pk4?apiKey=caa854bcf02f1a45ec737cc926418472288799ed</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Do NOT share these links with anyone. They can be used to claim your runs."},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"base_model = \"/kaggle/input/llama-3.2/transformers/3b-instruct/1\"\nnew_model = \"llama-3.2-3b-it-Ecommerce-ChatBot\"\ndataset_name = \"bitext/Bitext-customer-support-llm-chatbot-training-dataset\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T14:19:43.344471Z","iopub.execute_input":"2025-05-09T14:19:43.345029Z","iopub.status.idle":"2025-05-09T14:19:43.348199Z","shell.execute_reply.started":"2025-05-09T14:19:43.345005Z","shell.execute_reply":"2025-05-09T14:19:43.347555Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Set torch dtype and attention implementation\nif torch.cuda.get_device_capability()[0] >= 8:\n    !pip install -qqq flash-attn\n    torch_dtype = torch.bfloat16\n    attn_implementation = \"flash_attention_2\"\nelse:\n    torch_dtype = torch.float16\n    attn_implementation = \"eager\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T14:19:43.349013Z","iopub.execute_input":"2025-05-09T14:19:43.349257Z","iopub.status.idle":"2025-05-09T14:19:43.360758Z","shell.execute_reply.started":"2025-05-09T14:19:43.349232Z","shell.execute_reply":"2025-05-09T14:19:43.360115Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# QLoRA config\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch_dtype,\n    bnb_4bit_use_double_quant=True,\n)\n# Load model\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    attn_implementation=attn_implementation\n)\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T14:19:46.014894Z","iopub.execute_input":"2025-05-09T14:19:46.015334Z","iopub.status.idle":"2025-05-09T14:19:53.760995Z","shell.execute_reply.started":"2025-05-09T14:19:46.015313Z","shell.execute_reply":"2025-05-09T14:19:53.760206Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fe508bf29a947e7966eb06258e4836c"}},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"#Importing the dataset\ndataset = load_dataset(dataset_name, split=\"train\")\ndataset = dataset.shuffle(seed=65).select(range(1000)) # Only use 1000 samples for quick demo\ninstruction = \"\"\"You are a top-rated customer service agent named John. \n    Be polite to customers and answer all their questions.\n    \"\"\"\ndef format_chat_template(row):\n    \n    row_json = [{\"role\": \"system\", \"content\": instruction },\n               {\"role\": \"user\", \"content\": row[\"instruction\"]},\n               {\"role\": \"assistant\", \"content\": row[\"response\"]}]\n    \n    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n    return row\n\ndataset = dataset.map(\n    format_chat_template,\n    num_proc= 4,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T14:22:05.444225Z","iopub.execute_input":"2025-05-09T14:22:05.444797Z","iopub.status.idle":"2025-05-09T14:22:07.225415Z","shell.execute_reply.started":"2025-05-09T14:22:05.444777Z","shell.execute_reply":"2025-05-09T14:22:07.224734Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7076da68f2734bd5aed963e8afce483a"}},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"dataset = dataset.train_test_split(test_size=0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T14:23:58.406652Z","iopub.execute_input":"2025-05-09T14:23:58.406945Z","iopub.status.idle":"2025-05-09T14:23:58.419727Z","shell.execute_reply.started":"2025-05-09T14:23:58.406925Z","shell.execute_reply":"2025-05-09T14:23:58.419015Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T14:24:00.165007Z","iopub.execute_input":"2025-05-09T14:24:00.165316Z","iopub.status.idle":"2025-05-09T14:24:00.170427Z","shell.execute_reply.started":"2025-05-09T14:24:00.165295Z","shell.execute_reply":"2025-05-09T14:24:00.169728Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['flags', 'instruction', 'category', 'intent', 'response', 'text'],\n        num_rows: 900\n    })\n    test: Dataset({\n        features: ['flags', 'instruction', 'category', 'intent', 'response', 'text'],\n        num_rows: 100\n    })\n})"},"metadata":{}}],"execution_count":38},{"cell_type":"markdown","source":"## Setting up the Model","metadata":{}},{"cell_type":"code","source":"import bitsandbytes as bnb\n\ndef find_all_linear_names(model):\n    cls = bnb.nn.Linear4bit\n    lora_module_names = set()\n    for name, module in model.named_modules():\n        if isinstance(module, cls):\n            names = name.split('.')\n            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n    if 'lm_head' in lora_module_names:  # needed for 16 bit\n        lora_module_names.remove('lm_head')\n    return list(lora_module_names)\n\nmodules = find_all_linear_names(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T14:19:58.676275Z","iopub.execute_input":"2025-05-09T14:19:58.676540Z","iopub.status.idle":"2025-05-09T14:19:58.681888Z","shell.execute_reply.started":"2025-05-09T14:19:58.676519Z","shell.execute_reply":"2025-05-09T14:19:58.681262Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"#### LoRA Configuration","metadata":{}},{"cell_type":"code","source":"# LoRA config\npeft_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=modules\n)\ntokenizer.chat_template = None\nmodel, tokenizer = setup_chat_format(model, tokenizer)\nmodel = get_peft_model(model, peft_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T14:20:01.156859Z","iopub.execute_input":"2025-05-09T14:20:01.157349Z","iopub.status.idle":"2025-05-09T14:20:02.439298Z","shell.execute_reply.started":"2025-05-09T14:20:01.157320Z","shell.execute_reply":"2025-05-09T14:20:02.438486Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"hyperparameters for training","metadata":{}},{"cell_type":"code","source":"#Hyperparamter\ntraining_arguments = TrainingArguments(\n    output_dir=new_model,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=2,\n    optim=\"paged_adamw_32bit\",\n    num_train_epochs=1,\n    eval_strategy=\"steps\",\n    eval_steps=0.2,\n    logging_steps=1,\n    warmup_steps=10,\n    logging_strategy=\"steps\",\n    learning_rate=2e-4,\n    fp16=False,\n    bf16=False,\n    group_by_length=True,\n    report_to=\"wandb\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T14:20:04.553869Z","iopub.execute_input":"2025-05-09T14:20:04.554437Z","iopub.status.idle":"2025-05-09T14:20:04.585684Z","shell.execute_reply.started":"2025-05-09T14:20:04.554413Z","shell.execute_reply":"2025-05-09T14:20:04.585149Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"SFT trainer setup","metadata":{}},{"cell_type":"code","source":"# Setting sft parameters\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    peft_config=peft_config,\n    # max_seq_length= 512,\n    # dataset_text_field=\"text\",\n    # tokenizer=tokenizer,\n    args=training_arguments,\n    # packing= False,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T14:24:47.800562Z","iopub.execute_input":"2025-05-09T14:24:47.801346Z","iopub.status.idle":"2025-05-09T14:24:49.879736Z","shell.execute_reply.started":"2025-05-09T14:24:47.801320Z","shell.execute_reply":"2025-05-09T14:24:49.879094Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Converting train dataset to ChatML:   0%|          | 0/900 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ed3f5839b2f44b391d75198c3361a56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Adding EOS to train dataset:   0%|          | 0/900 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"524e0e8746c44531bbf73387ddd8e78d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset:   0%|          | 0/900 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efeee6d8ff10479e96360ce13505b7af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Truncating train dataset:   0%|          | 0/900 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8340178c372547689359bb44db607cd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Converting eval dataset to ChatML:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33a3f1a16db54eddb69ff3a0e773a6a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Adding EOS to eval dataset:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d22377dae1045c9b343602a2dbbe180"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing eval dataset:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00ba521235f741f2ad9a560aac4a42e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Truncating eval dataset:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6afb7b0655c74e3b985a2d0aa374e156"}},"metadata":{}},{"name":"stderr","text":"No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T14:25:26.809920Z","iopub.execute_input":"2025-05-09T14:25:26.810434Z","iopub.status.idle":"2025-05-09T14:34:45.469279Z","shell.execute_reply.started":"2025-05-09T14:25:26.810410Z","shell.execute_reply":"2025-05-09T14:34:45.468524Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='450' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [450/450 09:15, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>90</td>\n      <td>0.792500</td>\n      <td>0.709760</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.549700</td>\n      <td>0.638253</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>0.649500</td>\n      <td>0.611794</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.639900</td>\n      <td>0.584571</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.445700</td>\n      <td>0.566121</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=450, training_loss=0.682641639245881, metrics={'train_runtime': 557.7367, 'train_samples_per_second': 1.614, 'train_steps_per_second': 0.807, 'total_flos': 3105799910172672.0, 'train_loss': 0.682641639245881})"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"wandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T14:34:56.163831Z","iopub.execute_input":"2025-05-09T14:34:56.164454Z","iopub.status.idle":"2025-05-09T14:34:56.735663Z","shell.execute_reply.started":"2025-05-09T14:34:56.164428Z","shell.execute_reply":"2025-05-09T14:34:56.735071Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▅▃▂▁</td></tr><tr><td>eval/mean_token_accuracy</td><td>▁▄▅▇█</td></tr><tr><td>eval/num_tokens</td><td>▁▃▅▆█</td></tr><tr><td>eval/runtime</td><td>█▃▁▂▄</td></tr><tr><td>eval/samples_per_second</td><td>▁▆█▇▅</td></tr><tr><td>eval/steps_per_second</td><td>▁▆█▇▅</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇█</td></tr><tr><td>train/grad_norm</td><td>▅█▃▄▄▄▄▃▄▃▄▂▄▂▃▄▄▃▇▃▄▂▃▃▃▁▁▃▃▃▅▅▁▂▃▃▃▂▃▂</td></tr><tr><td>train/learning_rate</td><td>▂█████▇▇▇▇▇▇▇▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>██▅▅▆▄▆▅▅▇▅▅▅▄▅▅▄▃▃▄▄▃▂▃▁▂▄▂▅▄▄▃▄▃▂▄▅▂▆▅</td></tr><tr><td>train/mean_token_accuracy</td><td>▂▃▃▂▁▆▆▅▆▄▃▃▅▅▄▄▆▇▆▃▆▆▇█▄▅▇▆▆▅▄▅███▃▆▆▄▄</td></tr><tr><td>train/num_tokens</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.56612</td></tr><tr><td>eval/mean_token_accuracy</td><td>0.82924</td></tr><tr><td>eval/num_tokens</td><td>182069</td></tr><tr><td>eval/runtime</td><td>22.0205</td></tr><tr><td>eval/samples_per_second</td><td>4.541</td></tr><tr><td>eval/steps_per_second</td><td>4.541</td></tr><tr><td>total_flos</td><td>3105799910172672.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>450</td></tr><tr><td>train/grad_norm</td><td>1.15723</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4457</td></tr><tr><td>train/mean_token_accuracy</td><td>0.85087</td></tr><tr><td>train/num_tokens</td><td>182069</td></tr><tr><td>train_loss</td><td>0.68264</td></tr><tr><td>train_runtime</td><td>557.7367</td></tr><tr><td>train_samples_per_second</td><td>1.614</td></tr><tr><td>train_steps_per_second</td><td>0.807</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">helpful-oath-2</strong> at: <a href='https://wandb.ai/nanew/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/nhky0pk4?apiKey=caa854bcf02f1a45ec737cc926418472288799ed' target=\"_blank\">https://wandb.ai/nanew/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/nhky0pk4?apiKey=caa854bcf02f1a45ec737cc926418472288799ed</a><br> View project at: <a href='https://wandb.ai/nanew/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset?apiKey=caa854bcf02f1a45ec737cc926418472288799ed' target=\"_blank\">https://wandb.ai/nanew/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset?apiKey=caa854bcf02f1a45ec737cc926418472288799ed</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250509_141936-nhky0pk4/logs</code>"},"metadata":{}}],"execution_count":44},{"cell_type":"markdown","source":"### Model Inferencec","metadata":{}},{"cell_type":"code","source":"messages = [{\"role\": \"system\", \"content\": instruction},\n    {\"role\": \"user\", \"content\": \"I bought the same item twice, cancel order {{Order Number}}\"}]\n\nprompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    \ninputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n\noutputs = model.generate(**inputs, max_new_tokens=150, num_return_sequences=1)\n\ntext = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nprint(text.split(\"assistant\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T14:36:01.418558Z","iopub.execute_input":"2025-05-09T14:36:01.419338Z","iopub.status.idle":"2025-05-09T14:36:18.755189Z","shell.execute_reply.started":"2025-05-09T14:36:01.419303Z","shell.execute_reply":"2025-05-09T14:36:18.754500Z"}},"outputs":[{"name":"stdout","text":"\nI'm sorry to hear that you purchased the same item twice and are seeking to cancel your order with the number {{Order Number}}. I understand that this may have caused you inconvenience and I'm here to assist you. To cancel your order, I recommend reaching out to our customer support team. They will be able to guide you through the process and ensure that your order is cancelled promptly. You can contact our customer support team at {{Customer Support Phone Number}} or through the Live Chat on our website at {{Website URL}}. Rest assured, we value your satisfaction and will work towards resolving this matter for you.\n","output_type":"stream"}],"execution_count":46},{"cell_type":"markdown","source":"### Saving the tokeniser and model","metadata":{}},{"cell_type":"code","source":"# Save the fine-tuned model\ntrainer.model.save_pretrained(new_model)\ntrainer.model.push_to_hub(new_model, use_temp_dir=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T14:36:56.148940Z","iopub.execute_input":"2025-05-09T14:36:56.149655Z","iopub.status.idle":"2025-05-09T14:37:52.797444Z","shell.execute_reply.started":"2025-05-09T14:36:56.149631Z","shell.execute_reply":"2025-05-09T14:37:52.796833Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/1.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71ca56c659174c9093c5de37f37e0371"}},"metadata":{}},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/nerdasss/llama-3.2-3b-it-Ecommerce-ChatBot/commit/d2817e3d02dc76c05d0c9057c2350b92f2e77e23', commit_message='Upload model', commit_description='', oid='d2817e3d02dc76c05d0c9057c2350b92f2e77e23', pr_url=None, repo_url=RepoUrl('https://huggingface.co/nerdasss/llama-3.2-3b-it-Ecommerce-ChatBot', endpoint='https://huggingface.co', repo_type='model', repo_id='nerdasss/llama-3.2-3b-it-Ecommerce-ChatBot'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}